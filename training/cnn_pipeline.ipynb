{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fac2b2ec-cb02-41cb-bc4d-13e90d00e9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/sdm-geolifeCLEF/models\n",
      "/home/jovyan/sdm-geolifeCLEF/raster\n",
      "/home/jovyan/sdm-geolifeCLEF/training\n",
      "/srv/conda/envs/notebook/lib/python39.zip\n",
      "/srv/conda/envs/notebook/lib/python3.9\n",
      "/srv/conda/envs/notebook/lib/python3.9/lib-dynload\n",
      "\n",
      "/srv/conda/envs/notebook/lib/python3.9/site-packages\n",
      "/home/jovyan/sdm-geolifeCLEF/training\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# from dask.distributed import Client\n",
    "# from dask_gateway import GatewayCluster\n",
    "\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "current_folder = os.getcwd()\n",
    "sys.path.insert(0, '/home/jovyan/sdm-geolifeCLEF/raster')\n",
    "sys.path.insert(0, '/home/jovyan/sdm-geolifeCLEF/models')\n",
    "\n",
    "from inception_env import InceptionEnv\n",
    "\n",
    "import sys\n",
    "for path in sys.path:\n",
    "    print(path)\n",
    "print(current_folder)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac8305fd-de20-43c1-8f6f-2f3f0d1e3fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "608a5001-6148-4163-91fe-42e8e01127f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from zarr_dataset import Zarr_Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5e9449-ad89-4b29-818a-858630005983",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read Zarr Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f6527c-262d-4b57-8ad0-75f8b697e472",
   "metadata": {},
   "source": [
    "## KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "196a6752-b281-4f12-ba34-d7fe7c505347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://datasets-sdm2/geoLifeCLEF/features/train_ca.zarr s3://datasets-sdm2/geoLifeCLEF/features/val_ca.zarr s3://datasets-sdm2/geoLifeCLEF/features/example.zarr ../data/val_ca.zarr ../data/train_ca.zarr\n"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME = 'datasets-sdm2'\n",
    "folder = 'geoLifeCLEF/features'\n",
    "# s3://datasets-sdm2/geoLifeCLEF/features/\n",
    "filename_train = 'train_ca.zarr'\n",
    "filename_val   = 'val_ca.zarr'\n",
    "s3_train_path  = 's3://{}/{}/{}'.format(BUCKET_NAME, folder, filename_train)\n",
    "s3_val_path    = 's3://{}/{}/{}'.format(BUCKET_NAME, folder, filename_val)\n",
    "local_val_path = '../data/val_ca.zarr'\n",
    "local_train_path = '../data/train_ca.zarr'\n",
    "s3_example_path = 's3://{}/{}/example.zarr'.format(BUCKET_NAME, folder)\n",
    "print(s3_train_path, s3_val_path, s3_example_path, local_val_path, local_train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2db1a0-c9bb-4af9-876c-8070b9f14e45",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup Train dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "563c9cea-a529-4200-a1d1-2aa052f71cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = Zarr_Dataset(s3_train_path)\n",
    "train_dataset = Zarr_Dataset(local_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dc0ca63-6ed0-4996-82a6-55194899afe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"zarr-info\"><tbody><tr><th style=\"text-align: left\">Type</th><td style=\"text-align: left\">zarr.core.Array</td></tr><tr><th style=\"text-align: left\">Data type</th><td style=\"text-align: left\">object</td></tr><tr><th style=\"text-align: left\">Shape</th><td style=\"text-align: left\">(17173, 2)</td></tr><tr><th style=\"text-align: left\">Chunk shape</th><td style=\"text-align: left\">(10, 2)</td></tr><tr><th style=\"text-align: left\">Order</th><td style=\"text-align: left\">C</td></tr><tr><th style=\"text-align: left\">Read-only</th><td style=\"text-align: left\">True</td></tr><tr><th style=\"text-align: left\">Filter [0]</th><td style=\"text-align: left\">Pickle(protocol=5)</td></tr><tr><th style=\"text-align: left\">Compressor</th><td style=\"text-align: left\">Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0)</td></tr><tr><th style=\"text-align: left\">Synchronizer type</th><td style=\"text-align: left\">zarr.sync.ThreadSynchronizer</td></tr><tr><th style=\"text-align: left\">Store type</th><td style=\"text-align: left\">zarr.storage.DirectoryStore</td></tr><tr><th style=\"text-align: left\">No. bytes</th><td style=\"text-align: left\">274768 (268.3K)</td></tr><tr><th style=\"text-align: left\">No. bytes stored</th><td style=\"text-align: left\">13232467047 (12.3G)</td></tr><tr><th style=\"text-align: left\">Storage ratio</th><td style=\"text-align: left\">0.0</td></tr><tr><th style=\"text-align: left\">Chunks initialized</th><td style=\"text-align: left\">1718/1718</td></tr></tbody></table>"
      ],
      "text/plain": [
       "Type               : zarr.core.Array\n",
       "Data type          : object\n",
       "Shape              : (17173, 2)\n",
       "Chunk shape        : (10, 2)\n",
       "Order              : C\n",
       "Read-only          : True\n",
       "Filter [0]         : Pickle(protocol=5)\n",
       "Compressor         : Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0)\n",
       "Synchronizer type  : zarr.sync.ThreadSynchronizer\n",
       "Store type         : zarr.storage.DirectoryStore\n",
       "No. bytes          : 274768 (268.3K)\n",
       "No. bytes stored   : 13232467047 (12.3G)\n",
       "Storage ratio      : 0.0\n",
       "Chunks initialized : 1718/1718"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34de5399-a023-434f-998e-0a346dca3279",
   "metadata": {},
   "source": [
    "### Quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cca77894-231c-492b-8d26-0cae386df629",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = train_dataset[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d40ebc2b-acf1-4f63-8749-22776bde0a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5079, 31)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = train_dataset[-1]\n",
    "N_LABELS = demo[1].shape[0]\n",
    "N_INPUTS = demo[0].shape[0]\n",
    "N_LABELS, N_INPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d0c5ff-a8e4-4e57-92c1-56bedbe6d060",
   "metadata": {},
   "source": [
    "## Setup Validation dataset and dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d6da4b-f026-4de3-b639-7bffba09a220",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Validate \n",
    "\n",
    "Ascertain accuracy of models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a7e08-2e30-4aa1-a5dd-976c2bedcf94",
   "metadata": {},
   "source": [
    "Load model from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6db4960e-63cc-4326-b46e-c7a20592756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainAccuracyTopK(predictions, labels, k:int=30, one_hot:bool=True):\n",
    "\n",
    "    \"\"\"Returns a '1' for every time a value in the top-k of predicitons is present in the \n",
    "       top-k of labels. This is then normalized by the number of predictions\n",
    "       results can have a maximum value of 1.0\n",
    "       params:\n",
    "           - predictions: tensor of [batch_size, num_classes]\n",
    "           - labels: tensor of [batch_size, num_classes]\n",
    "    \"\"\"\n",
    "    \n",
    "    res = 0.\n",
    "    batch_size = labels.shape[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i, pred in enumerate(predictions):\n",
    "        top_k_preds = np.argpartition(pred,-k)[-k:]\n",
    "        \n",
    "        if not one_hot:\n",
    "            top_k_labels = np.argpartition(labels[i],-k)[-k:]\n",
    "\n",
    "            if top_k_preds in top_k_labels:\n",
    "                res += 1.\n",
    "        else:\n",
    "            # There's only one-winner for 1 hot encoded\n",
    "            # top_k_labels = np.argpartition(labels[i],-1)[-1:]\n",
    "            top_k_labels = np.argmax(labels[i])\n",
    "            \n",
    "            if top_k_labels in top_k_preds:\n",
    "                res += 1.\n",
    "                # print(\"[{}] top_k label = {} | top_k preds = {}\".format(i,top_k_labels,top_k_preds))\n",
    "                # print (res, labels.shape[0])\n",
    "    return res / labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fd44d4b-f2ef-43b1-9580-6b3a48d30765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader, device, batch_size, validation_size=-1):\n",
    "    \"\"\"\n",
    "        Give the prediction of the model on a test set\n",
    "        :param model: the model\n",
    "        :param test_loader: the test set loader\n",
    "        :param validation_size: number of occurrences for the validation\n",
    "    \"\"\"\n",
    "    \n",
    "    validation_size = validation_size / batch_size if validation_size > -1 else -1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        y_preds = []\n",
    "        y_labels = []\n",
    "        count = 0\n",
    "        \n",
    "        for inputs, labels in tqdm(loader, leave=False):\n",
    "            \n",
    "            y_labels.extend(labels)\n",
    "            \n",
    "            # inputs, labels = inputs.type(torch.cuda.FloatTensor).to(device), labels.to(device)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # if(count % 100 == 0):\n",
    "            #     print(outputs.shape, outputs.dtype)\n",
    "                \n",
    "            y_preds.extend(outputs.cpu())\n",
    "\n",
    "            # y_preds.extend(outputs.cpu().tolist())\n",
    "            # y_preds.extend(outputs.data.tolist())\n",
    "            # y_labels.extend(labels)\n",
    "\n",
    "            count += 1\n",
    "            if validation_size > -1 and count >= validation_size:\n",
    "                break\n",
    "\n",
    "        predictions, labels = np.asarray(y_preds, dtype=object), np.asarray(y_labels, dtype=object)\n",
    "\n",
    "    return predictions, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c8a74d2-d370-454d-9e9d-060c6d56b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "def validate (num_epochs, model, device, loader, batch_size=32, validation_size=-1, top_k=[30]):\n",
    "    \n",
    "    # model = model.to(device)\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "\n",
    "        predictions, labels = predict(model, loader, device,batch_size, validation_size)\n",
    "\n",
    "        # evatuate\n",
    "        res = []\n",
    "        for k in top_k:\n",
    "            acc = TrainAccuracyTopK(predictions, labels, k)\n",
    "            res.append(acc*100.)\n",
    "            print(\"Accuracy[top_k={}] = {:.4}%\".format(k,res[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f556f8-ef92-406f-b978-065d8946c0ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load val dataset into memory from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17d5c0b1-4ea9-4e32-b318-cb6c5a74c4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://datasets-sdm2/geoLifeCLEF/features/val_ca.zarr'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_val_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc78754c-00f6-420a-8d89-da9aa283bdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.7 s, sys: 4.17 s, total: 19.9 s\n",
      "Wall time: 53.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_dataset = Zarr_Dataset(s3_val_path, persist=True)\n",
    "# val_dataset = Zarr_Dataset(s3_example_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a475ff9-c3d1-4096-9774-49fbcc74aafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4964, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4020331e-a6d2-457f-bad8-443df4b41c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4964"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e789e51-5f52-4465-98d1-11868eff9308",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load into val dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2cbe8f49-a382-4a7a-88f1-3ee5420ec8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_dataset, shuffle=True, batch_size=64, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56d1201-b8e4-4f34-aabf-d03abf1f06d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Display datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e33c90d-1f37-4d4a-97ef-c2a98cc799b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# (patch, target) = train_set[2708]\n",
    "(patch, target) = val_dataset[2708]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c847b56-9578-43ad-a820-39619e4e811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch[4:,:,:].max(), patch[4:,:,:].min(), patch[0:3,:,:].max(), patch[0:3,:,:].min(), patch[3,:,:].max(), patch[3,:,:].min(), len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db98e6a-2c87-48c3-a5ea-ed6b5faaed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = patch[0:3,:,:]\n",
    "plt.imshow(img.permute(1, 2, 0), vmax=1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089d4638-4bfd-4ed9-a8e6-ecb15b3639bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "NIR_image = patch[3].unsqueeze(dim=0)#-> Remove first dim (channel) \n",
    "plt.imshow(NIR_image.permute(1, 2, 0),vmax=1)#, vmax=1.0)\n",
    "plt.colorbar()\n",
    "NIR_image.max(), patch[3].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beecaeb6-4c22-4563-92f6-2422f4922186",
   "metadata": {},
   "outputs": [],
   "source": [
    "ped = patch[-1].unsqueeze(dim=0)#-> Remove first dim (channel) \n",
    "plt.imshow(ped.permute(1, 2, 0),vmax=1)#, vmax=1.0)\n",
    "plt.colorbar()\n",
    "patch[3].min(), patch[3].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffe6e37-3d03-4736-ac8c-d2c5c14f3d4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train/predict setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e41ee93d-0c11-4a36-badb-597d79d48fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from train import fit\n",
    "# from predict import predict\n",
    "from evaluation import evaluate\n",
    "from metrics import ValidationAccuracyMultipleBySpecies\n",
    "from metrics import ValidationAccuracyMultiple\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "\n",
    "iterations = [20,40,60] #,80,100,120,140)\n",
    "#test\n",
    "iterations = [1]\n",
    "NUM_EPOCHS = iterations[-1]\n",
    "\n",
    "LOG_MODULO = 50 #\n",
    "VAL_MODULO = 5\n",
    "LR = 0.1\n",
    "# LR = 1e-2\n",
    "# LR = 5e-4 * batch_size / 256\n",
    "GAMMA = 0.1\n",
    "DROPOUT = 0.7\n",
    "\n",
    "MODEL = 'inet'\n",
    "OPTIM = 'SGD'\n",
    "\n",
    "# evaluation\n",
    "# METRICS = (ValidationAccuracyMultipleBySpecies([30]), ValidationAccuracyMultiple([30]))\n",
    "METRICS = (ValidationAccuracyMultiple([30,50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7251827-d282-47b9-889a-5bc074a64479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "# inet.to('cpu')\n",
    "# del inet\n",
    "# del train_set#, val_set\n",
    "# del train_loader#, val_loader\n",
    "# del val_dataset, val_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c92674e5-df74-44a6-93ef-dfa26f1761a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26f5bcc-1585-411f-92b2-7f5da18acbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_recent_loss = None\n",
    "train_loss = []\n",
    "completed_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "026aa67e-2d5b-48b1-b6b2-9e67f7345e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InceptionNet in mlmc mode"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inet = InceptionEnv(dropout=DROPOUT, n_labels=N_LABELS, n_input=N_INPUTS)\n",
    "inet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba71bbdc-a4fc-4d71-b0e8-413d0cc5db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "if OPTIM == 'SGD':\n",
    "    optimizer = torch.optim.SGD(inet.parameters(), lr=LR, momentum=0.9)\n",
    "else:\n",
    "    optimizer = torch.optim.AdamW(inet.parameters(), lr=LR, betas=(0.9, 0.95), weight_decay=0.1)\n",
    "\n",
    "scheduler = MultiStepLR(optimizer, milestones=iterations, gamma=GAMMA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40a38198-a469-46cb-a986-966727c1cf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "def train(model, train_loader, val_loader, num_epochs, criterion, optimizer, scheduler=None, val_modul0=1, completed_epochs=0):\n",
    "    \n",
    "    print('beginning to train model')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        running_loss = 0\n",
    "        start_time = time.perf_counter()\n",
    "        for inputs, labels in tqdm(train_loader, leave=False):\n",
    "            # print(\"Train loop dtypes: \", inputs.dtype, labels.dtype)\n",
    "            inputs, labels = inputs.type(torch.cuda.FloatTensor).to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "         \n",
    "        completed_epochs += 1\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "            \n",
    "        end_time = time.perf_counter()\n",
    "        duration = end_time - start_time\n",
    "        #train_acc = compute_accuracy(model, train_loader)\n",
    "        # val_acc = compute_accuracy(model, val_loader)\n",
    "        \n",
    "        train_loss.append(running_loss / len(train_loader))\n",
    "        \n",
    "        most_recent_loss = train_loss[-1]\n",
    "        \n",
    "        if val_loader and epoch % val_modulo == 0:\n",
    "            validate(1, model, val_loader, device, validation_size=1000)\n",
    "        \n",
    "        \n",
    "        print(\"Epoch: {0:02d} | Training Loss: {1:.5f} | Time: {2:.3f}\".format(epoch+1, most_recent_loss, duration))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7715d04-7a3a-4bc4-9726-d9505c15671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0eaed09b-ae9e-444a-a2a7-5a215ca370a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edba409c-450a-41d6-ac79-71da6fee11fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning to train model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3188e69f121456995257ef56317ef08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Training Loss: 1998.45385 | Time: 348.488\n"
     ]
    }
   ],
   "source": [
    "train(model=inet, train_loader=train_loader, val_loader=None, num_epochs=NUM_EPOCHS, criterion=criterion, optimizer=optimizer, scheduler=scheduler)\n",
    "# train(inet, train_loader, None, NUM_EPOCHS, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa18321-43cf-44c3-b294-22595aa3d623",
   "metadata": {},
   "source": [
    "## Save model states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f411d668-c83e-462b-8af7-60f56bc2c10b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "dfc5a456-9fd1-42f6-b23f-bf39aa724b51",
   "metadata": {},
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1733a3f-fc86-4612-a697-22b89c6eca6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inet_20221212-124-b128-e0-SGD.tar'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "date = datetime.datetime.strptime(str(datetime.datetime.now()), \"%Y-%m-%d  %H:%M:%S.%f\")\n",
    "\n",
    "filename_model = 'inet_{}{}{}-{}{}-b{}-e{}-{}.tar'.format(date.year, date.month, date.day, date.hour, date.minute, BATCH_SIZE, completed_epochs, OPTIM)\n",
    "filename_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8cd288e2-e019-4be7-a20b-408b70f31ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s3://datasets-sdm2/geoLifeCLEF/models/inet/inet_20221212-124-b128-e0-SGD.tar',\n",
       " 'models/inet_20221212-124-b128-e0-SGD.tar')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUCKET_NAME = 'datasets-sdm2'\n",
    "folder = 'geoLifeCLEF/models/inet'\n",
    "# s3://datasets-sdm2/geoLifeCLEF/models/inet/\n",
    "\n",
    "s3_model_path  = 's3://{}/{}/{}'.format(BUCKET_NAME, folder, filename_model)\n",
    "local_model_path = 'models/' + filename_model\n",
    "s3_model_path, local_model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b28a739a-1e19-4b07-a934-bc0f328eeefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(PATH, model, optimizer):\n",
    "    \n",
    "    if scheduler:\n",
    "        ssd = scheduler.state_dict()\n",
    "    else:\n",
    "        ssd = None\n",
    "        \n",
    "    torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': ssd,\n",
    "            'loss': train_loss,\n",
    "            'NUM_EPOCHS' : NUM_EPOCHS,\n",
    "            'BATCH_SIZE' : BATCH_SIZE,\n",
    "            'GAMMA' : GAMMA,\n",
    "            'LR' : LR,\n",
    "            'MODEL': MODEL,\n",
    "            'OPTIM' : OPTIM\n",
    "            }, PATH)\n",
    "    \n",
    "    \n",
    "def load_model(PATH):\n",
    "    checkpoint = torch.load(PATH)\n",
    "    \n",
    "    NUM_EPOCHS = checkpoint['NUM_EPOCHS'] if checkpoint['NUM_EPOCHS'] else None \n",
    "    BATCH_SIZE = checkpoint['BATCH_SIZE'] if checkpoint['BATCH_SIZE'] else None\n",
    "    GAMMA      = checkpoint['GAMMA'] if checkpoint['GAMMA'] else None\n",
    "    LR         = checkpoint['LR'] if checkpoint['LR'] else 1e-3\n",
    "    MODEL      = checkpoint['MODEL'] if checkpoint['MODEL'] else 'inet'\n",
    "    OPTIM      = checkpoint['OPTIM'] if checkpoint['OPTIM'] else 'AdamW'\n",
    "    \n",
    "    if MODEL == 'inet':\n",
    "        model = InceptionEnv(dropout=DROPOUT, n_labels=N_LABELS, n_input=N_INPUTS)\n",
    "        \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "    if OPTIM == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
    "    else:\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=LR, betas=(0.9, 0.95), weight_decay=0.1)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    if checkpoint['scheduler_state_dict']:\n",
    "        scheduler = MultiStepLR(optimizer, milestones=iterations, gamma=GAMMA)\n",
    "    else :\n",
    "        scheduler = None\n",
    "\n",
    "    train_loss = checkpoint['loss']\n",
    "    \n",
    "    return model, optimizer, scheduler, train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "838ff85a-b81c-4dfd-91b4-d11d3dd8907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(filename_model, inet, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c836a089-6516-4264-903b-f79526e889d0",
   "metadata": {},
   "source": [
    "# Validate after loading save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3954cf47-edf3-4c53-9d1e-fc8b3ac778e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LABELS = 5079\n",
    "N_INPUTS = 31\n",
    "GAMMA = 0.1\n",
    "DROPOUT = 0.7\n",
    "NUM_WORKERS = 8\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7318f4bb-7f3b-4dab-92aa-5e5d1d9f70d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a1080a5-2ebc-4994-9c39-73e5f5bbc43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'inet_20221211-14-59.pt'\n",
    "model_path = 'inet_20221211-5-38.pt'\n",
    "model_path = 'inet_20221211-21-9.pt'\n",
    "dict_path = 'inet_20221212-124-b128-e0-SGD.tar'\n",
    "\n",
    "inet, optimizer, scheduler, train_loss = load_model(dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ed30add-deea-41b8-b00d-636d0e69f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inet = inet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ca14ed95-bfb5-408b-a794-80891f81ef5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11ae292729e4867beb8279ab4edb5c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_432/2675298953.py:41: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  predictions, labels = np.asarray(y_preds, dtype=object), np.asarray(y_labels, dtype=object)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy[top_k=30] = 2.397%\n",
      "Accuracy[top_k=50] = 4.23%\n",
      "Accuracy[top_k=100] = 8.36%\n"
     ]
    }
   ],
   "source": [
    "validate(num_epochs=1, model=inet, loader=val_loader, device=device, validation_size=-1, top_k=[30,50,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687e0b22-2732-4952-9c75-c35b9a87db4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Test BCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2093c24a-0031-4b49-a478-21bcf0037a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ca_val_gdf.drop(['geometry'], axis=1).to_numpy()\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd217e-7de2-4464-a65f-296eb642289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "batch_size = 8\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "# outputs_before_sigmoid = torch.randn(batch_size, num_classes)\n",
    "fake_output = torch.randn(num_classes, dtype=float)\n",
    "sigmoid_outputs = torch.sigmoid(fake_output)\n",
    "softmax_outputs = F.softmax(fake_output, dim=-1)\n",
    "\n",
    "\n",
    "#or perfect guess\n",
    "outputs = torch.from_numpy(targets[5])\n",
    "\n",
    "target = torch.from_numpy(targets[5])\n",
    "# target_classes = torch.randint(0, 2, (batch_size, num_classes),dtype=torch.float)  # randints in [0, 2).\n",
    "\n",
    "# target_classes = torch.tensor([[1.0],[0.0]])\n",
    "# sigmoid_outputs = torch.tensor([[0.8],[0.]])\n",
    "print(len(sigmoid_outputs), len(target))\n",
    "print(type(sigmoid_outputs), type(torch.from_numpy(targets[5])))\n",
    "loss = loss_fn(sigmoid_outputs, target)\n",
    "loss2 = loss_fn(softmax_outputs, target)\n",
    "# loss = loss_fn(outputs, target)\n",
    "print(loss, loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188c3dbb-cf59-422a-97fd-3eb00f186cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_outputs.sum(), target.sum(), softmax_outputs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1a78fb-6230-4b57-bbce-ba9591b0d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ef0e3-f748-4fcf-a9a4-bdf135bd2789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import numcodecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f6f69-0e6a-4766-9e28-0d8185755201",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = zarr.empty(1, dtype=object, object_codec=numcodecs.Pickle())\n",
    "z[0] = [patch, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc57ff45-7c84-42d2-82be-9166cbf1aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "z[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ade6816-ea84-4f02-89b9-a47dfe9e8042",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Original Training for InceptioNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8452fc2c-71e6-46e1-b63f-9b5af8e40746",
   "metadata": {},
   "source": [
    "### Debug: setting paths for imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b04929-0503-48c8-9827-7b31dc2e0ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "for path in sys.path:\n",
    "    print(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f34055-9482-4f8c-9e66-7344aa17e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.remove('/models')\n",
    "# sys.path.remove('/raster')\n",
    "# sys.path.remove('model/')\n",
    "sys.path.remove('/home/jovyan/sdm-geolifeCLEF/../raster')\n",
    "# sys.path.remove('/models')\n",
    "# sys.path.remove('/raster')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65405a39-afb6-48ba-8b5e-d631bf0bd858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
